defaults:
    - base_optimizer
    - _self_

# optimization algorithm to use
type: "Adam"

# learning rate
lr: 0.001

# running average coefficients
beta1: 0.9
beta2: 0.999

# amount of weight decay on parameters
weight_decay: 0.0
